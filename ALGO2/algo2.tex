\documentclass[french]{article}
\usepackage[utf8x]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[french]{babel}
\usepackage{lmodern}
\usepackage{graphicx}
\usepackage{tikz}
\usepackage{fullpage}
\usepackage{caption}
\usepackage{subcaption}


\usepackage{float}

\usepackage{tabularx}

\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}

\title{Algorithmique 2}
\date{}
\author{L3 RI}

\newcommand{\TODO}{\textcolor{red}{\textbf{TODO}}}

\newcommand{\NP}{\mathrm{NP}}
\newcommand{\size}[1]{\vert #1 \vert}

\begin{document}
\maketitle
\tableofcontents

\section{NP-Complétude}

\subsection{Définitions}

\paragraph{Réduction} Soient $L_1$, $L_2$ des langages.
Une réduction polynomiale de $L_1$ à $L_2$ est une fonction $f$ calculable en temps polynomial telle que :
	\[ f(x) \in L_2 \Longleftrightarrow x \in L_1 \]
On note $L_1 \leq L_2$ ($L_1$ plus facile que $L_2$ = Si on sait résoudre $L_2$, on sait résoudre $L_1$)

\begin{figure}[H]
\center
\begin{tikzpicture}
\draw (1,0) -- (1,4) -- (7,4) -- (7,0) -- (1,0);
\draw (2,1) -- (2,3) -- (3,3) -- (3,1) -- (2,1);
\draw (4,1) -- (4,3) -- (6,3) -- (6,1) -- (4,1);
\draw[->] (0,2) -- (2,2);
\draw[->] (3,2) -- (4,2);
\draw[->] (6,2) -- (8,2);
\node[draw,line width=-1] at (0,2.2) {$x$};
\node[draw,line width=-1] at (2.5,2) {$f$};
\node[draw,line width=-1] at (5.6,1.2) {$L_2$};
\node[draw,line width=-1] at (6.6,0.2) {$L_1$};
\end{tikzpicture}
\caption{Schéma de réduction de $L_1$ à $L_2$}
\end{figure}

\paragraph{Classe NP}Soit $L$ un langage. $L$ est dit dans la classe NP s'il existe une machine de Turing non-déterministe en temps polynomial par rapport à la taille de l'entrée qui décide $L$.

\paragraph{NP-Complétude} Soit $L$ un langage. $L$ est dit NP-dur si pour tout $L' \in \NP$, $L' \leq L$.
$L$ est dit NP-complet si $L \in \NP$ et $L$ est NP-dur.

\paragraph{Remarques} Si un problème NP-complet est dans P, alors P = NP. Pour montrer que $L'$ est NP-dur, il suffit de montrer qu'il existe $L$ NP-dur tel que $L \leq L'$.

\subsection{Satisfiabilité d'une formule}

\vspace{0.5cm}
\begin{tabularx}{\textwidth}{p{1cm}X}
\multicolumn{2}{c}{\textbf{Problème de décision : SAT}} \\ 
\emph{Entrée} & $\varphi$ formule de la logique propositionnelle \\ 
\emph{Sortie} & Oui si $\varphi$ est satisfiable, c'est-à-dire s'il existe une valuation $v$ des variables qui rend $\varphi$ vraie \\
\end{tabularx}

\paragraph{Théorème de Cook} SAT est NP-complet. (\emph{Réduction de $L$ à SAT pour $L \in \NP$ en considérant une machine de Turing $\mathcal{M}$ non-déterministe qui décide $L$. On construit une formule qui traduit une exécution de $\mathcal{M}$.})

\vspace{0.5cm}
\begin{tabularx}{\textwidth}{X}
\multicolumn{1}{c}{\textbf{Problème de décision : $i$-SAT}} \\ 
Restriction de SAT à des formules en forme normale conjonctive (CNF) tel que chaque clause contient au plus $i$ littéraux \\
\end{tabularx}

\paragraph{Théorème} 3-SAT est NP-complet. (\emph{Réduction de SAT à 3-SAT.})

\paragraph{Théorème} 2-SAT est dans P. (\emph{Réduction de 2-SAT à la détermination des CFC d'un graphe.})

\vspace{0.5cm}
\begin{tabularx}{\textwidth}{p{1cm}X}
\multicolumn{2}{c}{\textbf{Problème de décision : MAX-2-SAT}} \\ 
\emph{Entrée} & $\varphi$ formule en 2-forme normale conjonctive et $k \in \mathbb{N}$ \\ 
\emph{Sortie} & Oui s'il existe une valuation qui satisfait au moins $k$ clauses de $\varphi$ \\
\end{tabularx}

\paragraph{Théorème} MAX-2-SAT est NP-complet. (\emph{Réduction de 3-SAT à MAX-2-SAT.})

\subsection{Graphes}

\vspace{0.5cm}
\begin{tabularx}{\textwidth}{p{1cm}X}
\multicolumn{2}{c}{\textbf{Problème de décision : ENS\_INDEP}} \\ 
\emph{Entrée} & $G = (V, E)$ un graphe non-orienté et $k \in \mathbb{N}$ \\ 
\emph{Sortie} & Oui s'il existe $V' \subseteq V$ tel que $\size{V'} = k$ et $(V' \times V') \cap E = \varnothing$ \\
\end{tabularx}

\paragraph{Théorème} ENS\_INDEP est NP-complet. (\emph{Réduction de 3-SAT à ENS\_INDEP.})


\vspace{0.5cm}
\begin{tabularx}{\textwidth}{p{1cm}X}
\multicolumn{2}{c}{\textbf{Problème de décision : MAX\_CUT}} \\ 
\emph{Entrée} & $G = (V, E)$ un graphe non-orienté et $k \in \mathbb{N}$ \\ 
\emph{Sortie} & Oui s'il existe $S_1$ et $S_2$, $S = S_1 \uplus S_2$ et $\# \lbrace (u,v) \in E ~\vert~ u \in S_1 \text{ et } v \in S_2 \rbrace \geq k$ \\
\end{tabularx}

\paragraph{Théorème} MAX\_CUT est NP-complet. (\emph{Réduction de MAX-2-SAT à MAX\_CUT}.)

\section{Algorithmes d'approximation}

\subsection{Définitions}

\paragraph{Problème de décision (DEC) $≠$ Problème d’optimisation (OPT)} 
\begin{itemize}


\item Un problème OPT (par exemple \og $x$ tel $f(x)$ minimal \fg) peut être traduit en un problème DEC (\og Pour un $b$ donné, existe-t’il $x$ tel que $f(x) \leq b$ ? \fg). 

\item OPT permet de résoudre DEC
\item Souvent, DEC permet de résoudre OPT par dichotomie.

\end{itemize}

\paragraph{Instance d’un problème d’optimisation} 
\begin{itemize}
\item ensemble de solution admissibles
\item coût pour chaque solution admissibles
\item hypothèse : il y a une solution de coût optimal $C^*$
\end{itemize}

\paragraph{Garantie de performance} Un algorithme d’approximation a une garantie de performance $\rho (n)$ (appelé facteur d’approximation) si \[\dfrac{C(\text{solution calculée})}{C^*} \leq \rho(n).\]

\subsection{Exemples}


\vspace{0.5cm}
\begin{tabularx}{\textwidth}{p{1cm}X}
\multicolumn{2}{c}{\textbf{Problème d’optimisation : VERTEX COVER}} \\ 
\emph{Entrée} & $G = (V,E)$ un graphe non orienté \\ 
\emph{Sortie} & $S \subset V$ de cardinal minimal tel que S couvre les arêtes de $G$, ie $\forall (v, v') \in E, v \notin S \implies v' \in S$\\
\end{tabularx}

\begin{figure}[H]
\centering

\begin{subfigure}[b]{0.3\textwidth}
\center
\begin{tikzpicture}
\node[draw, circle, fill=gray!50] (A) {};
\node[draw, circle, fill=gray!50] (B) at(1, 0) {};
\node[draw, circle] (C) at(2, 0) {};
\node[draw, circle, fill=gray!50] (D) at(3, 0) {};
\node[draw, circle] (E) at(0, 1) {};
\node[draw, circle] (F) at(1, 1) {};
\node[draw, circle] (G) at(2, 1) {};

\draw (A) -- (E);
\draw (E) -- (F);
\draw (F) -- (B);
\draw (B) -- (C);
\draw (F) -- (G);
\draw (G) -- (C);
\draw (G) -- (D);
\end{tikzpicture}
\subcaption{$S$ n’est pas admissible}
\end{subfigure}
\qquad
\begin{subfigure}[b]{0.3\textwidth}
\center
\begin{tikzpicture}
\node[draw, circle, fill=gray!50] (A) {};
\node[draw, circle, fill=gray!50] (B) at(1, 0) {};
\node[draw, circle, fill=gray!50] (C) at(2, 0) {};
\node[draw, circle, fill=gray!50] (D) at(3, 0) {};
\node[draw, circle, fill=gray!50] (E) at(0, 1) {};
\node[draw, circle] (F) at(1, 1) {};
\node[draw, circle, fill=gray!50] (G) at(2, 1) {};

\draw (A) -- (E);
\draw (E) -- (F);
\draw (F) -- (B);
\draw (B) -- (C);
\draw (F) -- (G);
\draw (G) -- (C);
\draw (G) -- (D);
\end{tikzpicture}
\subcaption{$S$ est une solution non optimale}
\end{subfigure}
\qquad
\begin{subfigure}[b]{0.3\textwidth}
\center
\begin{tikzpicture}
\node[draw, circle] (A) {};
\node[draw, circle, fill=gray!50] (B) at(1, 0) {};
\node[draw, circle] (C) at(2, 0) {};
\node[draw, circle] (D) at(3, 0) {};
\node[draw, circle, fill=gray!50] (E) at(0, 1) {};
\node[draw, circle] (F) at(1, 1) {};
\node[draw, circle, fill=gray!50] (G) at(2, 1) {};

\draw (A) -- (E);
\draw (E) -- (F);
\draw (F) -- (B);
\draw (B) -- (C);
\draw (F) -- (G);
\draw (G) -- (C);
\draw (G) -- (D);
\end{tikzpicture}
\subcaption{$S$ est une solution optimale}
\end{subfigure}

\caption{$S$ est constitué des nœuds grisés}
\end{figure}

\paragraph{Théorème} Le problème de décision associé à VERTEX COVER est NP-complet. (\emph{VERTEX COVER $\equiv$ ENS\_INDEP})


\paragraph{Théorème} Un algorithme glouton permet d’obtenir une $2$-approximation pour VERTEX COVER..

\vspace{0.5cm}
\begin{tabularx}{\textwidth}{p{1cm}X}
\multicolumn{2}{c}{\textbf{Problème d’optimisation : SET COVER}} \\ 
\emph{Entrée} & $X$ ensemble fini d’éléments, $\mathcal{F}$ une famille de sous ensembles de $X$.\\ 
\emph{Sortie} & $S \subset \mathcal{F}$ de cardinal minimal tel que S couvre tout $X$, ie $\forall x \in X, \exists ~ \mathcal{E} \in S $ tel que $x \in \mathcal{E}$\\
\end{tabularx}

\paragraph{Théorème} VERTEX COVER $\leq$ SET COVER


\paragraph{Théorème} Un algorithme glouton permet d’obtenir une $ln(n)$-approximation pour VERTEX COVER.


\vspace{0.5cm}
\begin{tabularx}{\textwidth}{p{1cm}X}
\multicolumn{2}{c}{\textbf{Problème d’optimisation : VOYAGEUR DU COMMERCE}} \\ 
\emph{Entrée} & $n$ villes, distances entre chaque ville\\ 
\emph{Sortie} & Une tournée qui minimise la distance parcourue.\\
\end{tabularx}

\paragraph{Théorème} Si P $\neq$ NP, alors pour toutes constante $\rho \geq 1$, il n’existe pas d’algorithme d’approximation polynomial de garantie de performance $\rho$ pour le voyageur de commerce.




\section{Algorithmes probabilistes}

\noindent Introduire de l’aléatoire pour :
\begin{itemize}
\item Réduire la complexité
\item Simplifier les algorithmes.
\end{itemize}
Contrepartie : solution approchée (avec bonne proba d’être près de l’optimale) ou complexité bonne en moyenne mais pas dans le pire des cas.

\subsection{Classes de complexité des algorithmes probabilistes}

\paragraph{ZPP : Zero Error Probabilistic Polynomial} Pour toute entrée de taille $n$, si il termine l’algo renvoie la réponse exacte et le temps moyen d’exécution et borné par $P(n)$, où $P$ est un polynôme. 

\emph{Exemple :} Random quick sort. 

\paragraph{RP : Randomized Polynomial} Pour toute entrée de taille $n$, l’algo $A$ s’exécute en temps borné par $P(n)$, ou $P$ est un polynôme, et si $x \in L$, $A$ répond \og oui \fg{} avec probabilité $\frac{1}{2}$, sinon il répond non avec probabilité $1$.

\emph{Exemple :} Random min cut. 

\paragraph{Théorème} RP $\subset$ NP.
\paragraph{Théorème} P $\subset$ ZPP.
\paragraph{Théorème} ZPP = RP $\cap$ co-RP.

\emph{Rappel :} $L \in $ co-RP $ \Longleftrightarrow $ $\Sigma^* \setminus L \in $ RP.




\section{Géométrie algorithmique}

\subsection{Enveloppe convexe}

\vspace{0.5cm}
\begin{tabularx}{\textwidth}{p{1cm}X}
\multicolumn{2}{c}{\textbf{Calcul de l'enveloppe convexe}} \\ 
\emph{Entrée} & Un ensemble $S$ de points $(x,y)$ du plan \\ 
\emph{Sortie} & $C \subseteq S$ une énumération dans le sens trigonométrique des points extrémaux de l'enveloppe convexe de S \\
\end{tabularx}

\begin{figure}[H]
\center
\begin{tikzpicture}
\draw (0,0) -- (2,0) -- (4,3) -- (2,5) -- (-2,4) -- (-3,3) -- (-2,1) -- (0,0);
\foreach \Point in {(2,1.5), (0,1), (2.5,3), (-1,2.5), (1,3), (0,0), (2,0), (4,3), (2,5), (-2,4), (-3,3), (-2,1), (.5,2), (2,3.2), (1.2,2.4)}{
    \node at \Point {\textbullet};
}
\end{tikzpicture}
\caption{Exemple d'enveloppe convexe d'un ensemble de points}
\end{figure}

\paragraph{Position d'un point par rapport à une droite} On suppose qu'il n'existe pas trois points alignés. $p_2$ est à gauche de la droite orientée $(\vec{p_0p_1})$ si et seulement si :
 \[ \det(\vec{p_0p_1}, \vec{p_0p_2}) > 0 \]
 
\paragraph{Marche de Jarvis} Algorithme du paquet cadeau
\begin{itemize}
	\item Partir du point de plus petite ordonnée $p_0$
	\item Prendre un point suivant, parcourir tous les points et le remplacer s'il en existe un plus à gauche de la droite orientée $(\vec{p_{actuel}~p_{suivant}})$
	\item Recommencer jusqu'à retomber sur $p_0$
\end{itemize}

\paragraph{Complexité de la marche de Jarvis} Si $n$ est la taille de $S$ et $h$ le nombre de points dans l'enveloppe convexe : $O(nh)$

La complexité dépend de la sortie (\emph{output sensitive}).


\paragraph{Balayage de Graham}\TODO

\paragraph{Complexité du balayage de Graham}\TODO

\subsection{Points les plus rapprochés}

\vspace{0.5cm}
\begin{tabularx}{\textwidth}{p{1cm}X}
\multicolumn{2}{c}{\textbf{Points les plus rapprochés}} \\ 
\emph{Entrée} & Un ensemble $S$ de points $(x,y)$ du plan \\ 
\emph{Sortie} & $d^*$ la distance minimale entre deux points de $S$ \\
\end{tabularx}

\paragraph{Algorithme}Principe de diviser pour régner, on divise le plan en deux. On obtient récursivement $\delta_D$ et $\delta_G$. Soit $\delta = \min (\delta_G, \delta_D)$. On considère l'ensemble $M$ des points dans la bande de largeur $2\delta$. $M = p_1 \ldots p_k$ énumérés par ordonnées croissantes.

\paragraph{Lemme}S'il existe $i < j$ tel que $d(p_i,p_j) < \delta$ alors il existe $i' < j' \leq i'+8$ tel que $d(p_{i'},p_{j'}) < \delta$.

En effet, on considère un rectangle qu'on divise en huit parties. On peut alors prendre 9 points et appliquer le principe des tiroirs.

\paragraph{Complexité} Pré-tris en $O(n \log n)$. Au total, avec le \emph{Master Theorem} : $O(n \log n)$

\section{Algorithmes distribués}

\subsection{Généralités}

\paragraph{}Un système distribué est constitué de \textbf{processus} communiquant par des objets de partage ou par \textbf{envoi de messages}.\\

\begin{itemize}
	\item \textbf{Communications}
	
	Asynchrones (pas de confirmation de réception du message)
	
	Par rendez-vous (Transmission uniquement sir le récepteur est prêt, problème d'interblocage)
	
	\item \textbf{Primitives} 
	
	Point à point
	
	broadcast
	
	\item \textbf{Topologie}
	
	Graphe fortement connexe
	
	Graphe complet
	
	\item \textbf{Degré de synchronie}
	
	Synchrone (horloges locales des processus son synchronisées, delai d'acheminement des message borné par $\Delta$, vitesse relative des processus bornée par $\phi$)
	
	Asynchrone ($\Delta$ et $\phi$ n'existent pas a priori)
	
	\item \textbf{Types de défaillances}
	
	Processus (crash, omission, byzantin)
	
	Liens de communication, perte de messages, altération, duplication, création
\end{itemize}

\subsection{Problème du consensus}

\paragraph{}Chaque processus $p_i$ a une valeur $v_i$ et une variale de décision $d_i$ initialement à $\perp$ qui est \emph{write once}.

\paragraph{}Un algorithme résout le consensus s'il garantit :
\begin{itemize}
	\item \textbf{Accord :} Si deux processus décident, alors ils décident la même valeur
	\item \textbf{Terminaison :} Tout processus correct va finalement décider
	\item \textbf{Validité :} Si $v$ est une valeur de décision d'un processus correct, alors $v$ était une valeur initiale
\end{itemize}

Si on ôte une des trois propriétés, le problème du consensus affaibli devient trivial.

\subsection{Consensus dans le cas synchrone}

\paragraph{}Si on formalise, un processus $p_i$ a un ensemble d'états ($states_i$), des états initiaux possibles ($start_i \subseteq states_i$) une fonction $msg_i$ qui à un état et un voisin associe un message (ou $null$) et une fonction de transition.
Un round est constitué d'une application de la fonction $msg_i$ et d'un envoi des messages aux destinataires, puis d'une réception des messages et une mise à jour de l'état courant.

\paragraph{}Un algorithme résout le problème du consensus et tolère t défaillances si pour toute exécution $\sigma$ telle que $f(\sigma) \leq t$ (nombre de défaillances au cours de $\sigma$), on a les trois propriétés : accord, terminaison, validité.

\paragraph{Algorithme Flood Set} Chaque processus commence avec $W_i = \lbrace v_i \rbrace$. Pour tout round d'indice inférieur à t, chaque processus envoie $W_i$ à tout le monde, et ajoute à $W_i$ ce qu'il reçoit des autres. Quand l'indice du round est $t + 1$, on décide $d_i = \min_i W_i$. L'algorithme Flood Set résout le problème du consensus pour les systèmes synchrones et tolère $t$ défaillances de type crash.

\paragraph{Preuve} Terminaison : décision au tour $t + 1$. Validité : à tout instant, $W_i$ contient des valeur initiales. Accord : Il existe un round sans crash, à l'issue de ce round tous les processus ont le même $W_i$, et l'égalité est conservée.


\subsection{Consensus dans le cas asynchrone}

\paragraph{Théorème de Fischer Lynch Paterson}Il n'existe pas d'algorithme résolvant le consensus dans le cas asynchrone qui tolère même une seule défaillance de type crash.

\paragraph{}\TODO formalisation, propriété du diamant, bivalence, étapes de la preuve (cf TD6)


\end{document}
